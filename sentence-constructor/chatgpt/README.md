# ChatGPT Sentence Constructor Activity

<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->
**Table of Contents**  *generated with [DocToc](https://github.com/thlorenz/doctoc)*

- [Method](#method)
- [Prompt](#prompt)
- [Results](#results)
  - [Portuguese (beginner level)](#portuguese-beginner-level)
    - [4o model (Portuguese)](#4o-model-portuguese)
    - [o1 model (Portuguese)](#o1-model-portuguese)
    - [Conclusion (Portuguese)](#conclusion-portuguese)
  - [French (intermediate level)](#french-intermediate-level)
    - [4o model (French)](#4o-model-french)
    - [o1 model (French)](#o1-model-french)
    - [Conclusion (French)](#conclusion-french)
  - [English (advanced level)](#english-advanced-level)
    - [4o model (English)](#4o-model-english)
    - [o1 model (English)](#o1-model-english)
    - [Conclusion (English)](#conclusion-english)
  - [Spanish (expert level)](#spanish-expert-level)
    - [4o model (Spanish)](#4o-model-spanish)
    - [o1 model (Spanish)](#o1-model-spanish)
    - [Conclusion (Spanish)](#conclusion-spanish)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

## Method

Models used: 4o and o1

Subscription: Plus plan (USD 20/month)

ChatGPT's **temporary chat** feature was used to prevent the model from [creating memories](https://openai.com/index/memory-and-new-controls-for-chatgpt/), which might pollute the model's future responses during experimentation. This allowed sending the same prompt more than once without the model remembering the previous interactions. The only drawback of using the temporary chat is the inability to see the chat after it has been closed, which makes the task of analyzing the model's performance more challenging.

The experiment was conducted in first person to simulate a student's perspective. The model was given a prompt to evaluate its suitability for the task. The model's response was then analyzed based on the prompt's requirements and the pedagogical value of the feedback provided.

## Prompt

We start evaluating the model's suitability for the task with a simple prompt. The prompt template was generated by ChatGPT itself, based on minimal instructions, and is as follows:

```text
You are my language tutor. I will write a sentence in [target language], and your role is to help me improve without giving me the answer directly.

If my sentence is correct, confirm that it is correct and suggest a small improvement if possible.

If my sentence has mistakes, point them out by explaining what kind of error I made (e.g., grammar, word choice, syntax), and give hints or examples to help me correct it myself without revealing the full correct sentence. Encourage me to try again, and only reveal the correct version if I struggle after a few attempts.

Keep your feedback friendly, supportive, and constructive to make learning engaging.
```

Note: The target language was replaced with the language being evaluated in each case.

## Results

### Portuguese (beginner level)

Sentence used: "Meu filho vai a escola todos os dias."
Translation: "My son goes to school every day."

#### 4o model (Portuguese)

First attempt: The model identified a small error in the preposition "a" (should be the contracted form "à") and provided helpful information to correct the error, including the grammar and hints using different sentences. Though the correct sentence was easy to infer from the feedback, the overall pedadogical value from such a simple prompt was very high.

Second attempt: The model identified the error but this time provided the correct solution. This is a stark contrast to the previous response, which was more pedagogically valuable.

#### o1 model (Portuguese)

Single attempt: After reasoning for 4 seconds, the model surprisingly replied in Portuguese! We never told the model that the student is at a beginner level, so it might have assumed the student was more advanced. The model's response would have been challenging for a beginner student but there is some pedagogical value to interacting in the target language. After the model's initial response, the test sentence was entered. The model reasoned for 20 seconds (!) and provided a concise response that was incredibly helpful. The model identified the error and provided a hint to correct it without giving away the solution. The model also provided positive reinforcement in far more professional tone than the 4o model: unlike the 4o model, it did not use emojis but rather a single sentence. Then, the correct sentence was entered, and true to its instructions, the model acknowledged the correct sentence and provided an improvement using more advanced vocabulary. The entire interaction was very professional and pedagogically valuable and it happened exclusively in Portuguese.

#### Conclusion (Portuguese)

The inconsistency in the 4o model's responses to the initial simple prompt makes the case for a more elaborate prompt or a more complex setup using OpenAI's API.

The o1 model's response was very thoughtful and pedagogically valuable. The model's ability to reason for 20 seconds and provide a concise response that was helpful and supportive is commendable. The model's ability to interact in the target language is a plus. Though it would have been challenging for a beginner student to interact exclusively in Portuguese, we never told the model the student's proficiency level. One significant drawback is the model's slow response time, which could be a hindrance in a real-time tutoring scenario, as well as the model's cost, which is higher than the 4o model and might not be justifiable for this task.

### French (intermediate level)

Sentence used: "J'aimerai bien voyager par tout le monde, dégoûter les plusieurs cuisines, et apprendre plusieurs langues."
Corrected sentence: "J'aimerais bien voyager à travers le monde, goûter plusieurs cuisines, et apprendre plusieurs langues."
Translation: "I would like to travel around the world, taste many cuisines, and learn many languages."

#### 4o model (French)

Single attempt: The model identified four errors and provided feedback for each.

1. “J’aimerai” → “J’aimerais”
    - This is a common mistake! “J’aimerais” is the correct conditional form of “aimer” (meaning “I would like”), while “J’aimerai” is the future tense (meaning “I will love”). Since you’re expressing a wish, the conditional “J’aimerais” is the right choice.
2. “par tout le monde” → ?
    - “Par tout” is incorrect here. Think about how you would say “all around the world” in French. A more natural phrase would be something like “à travers le monde” or “dans le monde entier”.
3. “dégoûter” → ?
    - Be careful! “Dégoûter” means “to disgust” rather than “to taste”. You need a verb that means “to try food”—do you know which one?
4. “les plusieurs cuisines” → ?
    - “Les” is unnecessary before “plusieurs” because “plusieurs” already means “several” on its own. So, you just need “plusieurs cuisines”.

The feedback is generally helpful. The model’s tone is friendly and supportive, and it encourages the student to try again. The model does not provide the correct sentence, which is in line with the prompt’s requirements. It understood the intended meaning of the sentence and provided feedback accordingly.

After entering the corrected sentence, the model acknowledged the correction and suggested using "découvrir" instead of "goûter" for the more nuanced meaning of not just tasting but also exploring different food cultures.

The model’s response was friendly and supportive, and provided excellent pedagogical value.

#### o1 model (French)

Single attempt: After reasoning for 27 seconds, the model identified the same four errors as the 4o model and provided feedback for each. Curiously, unlike during the Portuguese test, the model chose to interact in English.

1. Verb form: The conditional form of “I would like” isn’t spelled the way you wrote it. Look at the difference between the future tense and the conditional in French.
2. Expression for traveling: “Par tout le monde” sounds unnatural. Think of a more common way to say “around the world” or “throughout the world” in French.
3. Vocabulary: The verb you used before mentioning “cuisines” actually means “to disgust” or “repel.” There’s a very similar verb that means “to taste/appreciate food.”
4. Article + “plusieurs”: Typically, you don’t combine “les” with “plusieurs.” Consider removing or changing the article.

This response is more in line with the prompt’s requirements than the 4o model’s response. As observed during the Portuguese test, the o1 model’s response was concise, precise, and pedagogically valuable. The student is challenged to think and correct the errors themselves. The model asked whether more hints were needed.

After entering the corrected sentence, the model acknowledged the correction, noticed the repeated use of the word "plusieurs" and suggested a stylistic improvement to the same phrase as the 4o model: "you could say *goûter à de nombreuses cuisines* or *à différentes cuisines*—just to add variety to the wording.

It would appear from this last interaction that the 4o model was slightly more creative and—true to its label as a reasoning model—the o1 model was more cerebral. The o1 model's response was overall less playful than the 4o model's response. The former used no emojis and was more professional in tone, while the latter used emojis in the opening and closing paragraphs. The o1 model's response was more concise and to the point, which could be seen as a positive or negative depending on the student's preferences. Though it would be tempting to allow multiple styles, this could add complexity and costs to the project, so ultimately, the style would have to be dicatated by the organization's requirements.

#### Conclusion (French)

The 4o model's response was friendly, supportive, and provided excellent pedagogical value. The model's tone was engaging and encouraging, and the feedback was clear and helpful. The model's response was in line with the prompt's requirements and demonstrated an understanding of the intended meaning of the sentence.

The o1 model's response was concise, precise, and pedagogically valuable. The model's tone was professional and supportive, and the feedback was clear and helpful. The model's response was in line with the prompt's requirements and demonstrated an understanding of the intended meaning of the sentence. The model's response was more cerebral and less playful than the 4o model's response, which could be seen as a positive or negative depending on the student's preferences and the organization's requirements.

A more polished prompt could be used to evaluate the models further, but the initial results are promising.

### English (advanced level)

For the English test, ChatGPT's o1 and 4o models were used to generate a noun and a list of adjectives that describe the noun meaningfully and harmoniously. The model was asked specific adjectives categories and required to scramble the adjectives. This provided a challenging task for a highly proficient English speaker who is nonetheless a non-native speaker. It has been observed that while native speakers might naturally know the correct order of adjectives, non-native speakers might struggle with this task even at an advanced level. The tester meets this criterion and will attempt to create a sentence using the output from ChatGPT in a simple text editor without autocompletion or any other assistive writing technology. The rest of the experiment will be conducted per the initial prompt.

Noun: Akiya (An abandoned or vacant house in Japan)

Adjectives (scrambled and each from a different type):

- Wooden (Material)
- Faded (Color)
- Neglected (Opinion)
- Century-old (Age)
- Few (Quantity)
- Japanese (Origin)
- Gabled (Shape)
- Modest (Size)
- Rural (Type)
- Weathered (Physical Quality)

Sentence used: "Wouldn’t it be lovely to restore a single century-old neglected modest weathered gabled wooden rural faded Japanese akiya to its former glory?"

#### 4o model (English)

First attempt: The model did not point out any errors in the sequence of adjectives and instead suggested breaking up the sentence due to its length. While this is a valid suggestion, it did not address the student's main concern, which was never stated explicitly.

Second attempt: The model found the sentence to be "already well-constructed and grammatically correct", and added that it "effectively conveys a poetic and nostalgic feeling." However, the response continued, "the string of adjectives before 'akiya' is quite long, which can make the sentence feel a bit heavy." A possible improvement, according to the model, was to place a certain adjective before another one to make it flow more naturally. The model also suggested breaking up the sentence into two or more sentences or using punctation such as an em dash to improve it. While these are all valid suggestions, the model does not seem to have picked on the grammar rule that dictates the order of adjectives in English. Given this feedback, the student would have a hard time inferring the correct order of adjectives.

The model was then prompted to provide feedback on the correct order of adjectives, which it provided:

```text
1. Quantity → 2. Opinion → 3. Size → 4. Age → 5. Shape → 6. Color → 7. Origin → 8. Material → 9. Type/Purpose → Noun
```

The sentence included a determiner and 10 adjectives. The model's feedback was helpful and informative, but it was not provided in the initial response, which would have been more pedagogically valuable. It was also missing the "Physical Quality" category.

For comparison, here's the list that was originally used to generate the scrambled adjectives, which differs only slightly from the model's feedback.

1. Determiner: Words like a, the, my, some.
2. Quantity: Numbers or amounts like two, several.
3. Opinion: Descriptive words like beautiful, boring.
4. Size: Words indicating size like small, large.
5. Physical Quality: Descriptions of physical features like smooth, rough.
6. Shape: Forms like round, square.
7. Age: Descriptions of age like old, new.
8. Color: Colors like red, blue.
9. Origin: The place of origin like American, Chinese.
10. Material: What something is made of like wooden, metal.
11. Type: Categories like general-purpose, emergency.

[Source](https://englishstudyonline.org/order-of-adjectives/)

Further research and a reliable expert source would be needed to verify the accuracy of the list. However, for the purpose of this experiment, the conclusion is that the model's feedback was not as helpful as in the Portuguese and French tests.

Finally, the model suggested the following correction, along with a lengthy explanation, further ignoring the original instruction to not provide the correct sentence:

```text
Wouldn’t it be lovely to restore a single modest, neglected, weathered, century-old, faded, gabled, wooden, rural Japanese akiya to its former glory?
```

#### o1 model (English)

Single attempt: Consistent with previously observed behaviour, the o1 model responded concisely:

```text
That sentence is grammatically correct, and I can clearly see what you mean. One small improvement you could consider is to make the long string of adjectives a bit easier to read (for instance, by adding commas or changing their order). This can help the sentence flow more smoothly. Otherwise, you’ve got a solid sentence!
```

However, the model did not provide feedback on the order of adjectives, which was the main focus of the test. The model was then prompted to provide feedback on the correct order of adjectives. On this task, it performed much better than the 4o model. First, it provided a similar list to the 4o model with the order of 9 types of adjectives, but then it observed the guidance to not provide the correct sentence and instead provided a hint to the student to consider the categories of adjectives and their order. This was a more pedagogically valuable response than the 4o model's response.

```text
When you have many adjectives describing one noun, you can also add commas or use “and” to make the sentence easier to read. Here’s a hint for your sentence: try placing the more subjective or general adjectives first, then move on to details like age, condition, shape, material, and finally the origin or location. Feel free to experiment with where “neglected,” “weathered,” and “faded” go—they often fit near the beginning (condition) or close to color/appearance.
```

It is interesting to note that the o1 model did not comment on the "poetic" and "nostalgic" intent of the sentence, as the 4o model did. Once again, the o1 model's response was more professional and less playful than the 4o model's response. The o1 model's response was more concise and to the point, which could be seen as a positive or negative depending on the student's preferences and the organization's requirements.

#### Conclusion (English)

The 4o model's response provided limited pedagogical value.

The o1 model's response was more pedagogically valuable than the 4o model's response but still required a follow-up prompt to provide the correct order of adjectives.

This particular task would have required a more elaborate prompt that specifcally focused on the order of adjectives in English. The initial results are promising, but further testing is needed to evaluate the models' performance on more complex tasks.

### Spanish (expert level)

Sentence used: "El cardiólogo y la intensivista han determinado que, dada tu historia médica, la intervención más adecuada en tu caso es una angioplastia coronaria."
Translation: "The cardiologist and the intensivist have determined that, given your medical history, the most appropriate intervention in your case is a coronary angioplasty."

#### 4o model (Spanish)

Single attempt: The model initially replied in English, which was expected. When the test sentence in Spanish was entered, the model switched to Spanish, possibly detecting the highly sophisticated command of the target language by the user. It proceeded to make a minor but advanced improvement suggestion to replace “dada tu historia médica” por “dado tu historial médico” to use more precise medical vocabulary, consistent with the prompt's requirements and in line with the user's implied expert level of fluency. The model provided surprisingly high pedagogical value. Admiteedly, this was a bit of a stretch for the activity, but the model performed admirably. In reality, such as an advanced user would have likely queried the model directly in Spanish.

#### o1 model (Spanish)

Single attempt: The o1 model replied from the start in Spanish, as it did in the Portuguese test. The feedback was concise and also noted the same minor medical-context improvement as the 4o model. Curiously, the feedback felt warmer in tone than in other tests. It would be interesting to see if this is related to the Spanish language's cultural nuances or if it is a coincidence. The model's response was professional and pedagogically valuable in spite of the contrived nature of this particular test in relation to the sentence constructor activity.

#### Conclusion (Spanish)

Both models provided high pedagogical value and meaningful feedback at an expert level.
